# И Gu铆a Completa de Pruebas MCP

*Gu铆a paso a paso para probar todos los comandos MCP de la metodolog铆a*

##  Preparaci贸n Inicial

### 1. Ejecutar Script de Preparaci贸n
```bash
# Hacer ejecutable el script
chmod +x ejemplos-pruebas/test-mcp-commands.sh

# Ejecutar preparaci贸n autom谩tica
./ejemplos-pruebas/test-mcp-commands.sh
```

### 2. Verificar Configuraci贸n MCP
```bash
# Verificar que MCP est谩 configurado
cat .vscode/mcp.json

# Verificar servidores instalados
cd .ai-methodology/sync
npm run mcp:test
```

---

##  Pruebas de GitHub Project Manager

### **Comando 1: generate_prd**

#### **Objetivo:** Generar PRD desde una idea
#### **Input:** Idea de proyecto en texto libre
#### **Ejecuci贸n:**

1. **Abrir cliente MCP** (VS Code con Augment Code o Cursor)
2. **Ejecutar comando:**
   ```
   generate_prd "Sistema de Notificaciones Push: Implementar notificaciones en tiempo real via WebSocket, push notifications para m贸viles, email fallback, dashboard de administraci贸n, personalizaci贸n por usuario y analytics de engagement. Objetivos: mejorar engagement 40%, reducir churn 25%, implementar en 3 sprints."
   ```

#### **Output Esperado:**
- PRD completo en formato markdown
- Secciones: Resumen, objetivos, especificaciones, criterios de aceptaci贸n
- Timeline y estimaciones
- Riesgos y mitigaciones

#### **Validaci贸n:**
- [ ] PRD generado es coherente y completo
- [ ] Incluye objetivos de negocio claros
- [ ] Tiene criterios de aceptaci贸n espec铆ficos
- [ ] Timeline es realista

---

### **Comando 2: parse_prd**

#### **Objetivo:** Convertir PRD en tareas ejecutables
#### **Input:** Archivo PRD existente
#### **Ejecuci贸n:**

1. **Usar PRD de ejemplo:**
   ```
   parse_prd "ejemplos-pruebas/prd-ejemplo.md"
   ```

#### **Output Esperado:**
- Lista de tareas estructuradas
- Estimaciones de esfuerzo
- Dependencias entre tareas
- Criterios de aceptaci贸n por tarea

#### **Validaci贸n:**
- [ ] Tareas son espec铆ficas y ejecutables
- [ ] Estimaciones son razonables
- [ ] Dependencias est谩n identificadas
- [ ] Criterios de aceptaci贸n son testeable

---

### **Comando 3: sync_specs**

#### **Objetivo:** Sincronizar especificaciones con GitHub
#### **Input:** Especificaciones en directorio specs/
#### **Ejecuci贸n:**

1. **Verificar specs existentes:**
   ```bash
   ls specs/
   ```

2. **Ejecutar sincronizaci贸n:**
   ```
   sync_specs
   ```

#### **Output Esperado:**
- Issues creados en GitHub Projects
- Labels aplicados correctamente
- Estimaciones transferidas

#### **Validaci贸n:**
```bash
# Verificar issues creados
curl -H "Authorization: token $GITHUB_TOKEN" \
     https://api.github.com/repos/jivagrisma/dev-ia/issues

# Ver dashboard actualizado
cd .ai-methodology/sync && npm run dashboard
```

---

### **Comando 4: get_project_status**

#### **Objetivo:** Obtener estado actual del proyecto
#### **Input:** Ninguno (usa proyecto configurado)
#### **Ejecuci贸n:**

```
get_project_status
```

#### **Output Esperado:**
- Resumen de progreso
- Tareas abiertas/cerradas
- M茅tricas de velocidad
- Pr贸ximos milestones

#### **Validaci贸n:**
- [ ] Datos coinciden con dashboard local
- [ ] M茅tricas son precisas
- [ ] Estado refleja realidad del proyecto

---

##  Pruebas de Task Master AI

### **Comando 5: analyze_complexity**

#### **Objetivo:** Analizar complejidad de tareas
#### **Input:** Descripci贸n de tarea compleja
#### **Ejecuci贸n:**

1. **Tarea simple:**
   ```
   analyze_complexity "Agregar logging estructurado con Winston, diferentes niveles (debug, info, warn, error) y rotaci贸n autom谩tica de logs"
   ```

2. **Tarea compleja:**
   ```
   analyze_complexity "Implementar sistema de cache distribuido usando Redis cluster con invalidaci贸n inteligente, estrategias de clustering, monitoreo en tiempo real y fallback autom谩tico"
   ```

3. **Tarea 茅pica:**
   ```
   analyze_complexity "Migrar arquitectura monol铆tica a microservicios con comunicaci贸n as铆ncrona, service discovery, circuit breakers, distributed tracing y deployment automatizado"
   ```

#### **Output Esperado:**
- Score de complejidad (1-10 o story points)
- Factores de complejidad identificados
- Recomendaciones de divisi贸n
- Estimaci贸n de tiempo

#### **Validaci贸n:**
- [ ] Scores son consistentes con complejidad real
- [ ] Factores identificados son relevantes
- [ ] Recomendaciones son 煤tiles

---

### **Comando 6: breakdown_task**

#### **Objetivo:** Dividir tareas complejas en subtareas
#### **Input:** Tarea grande o 茅pica
#### **Ejecuci贸n:**

```
breakdown_task "Implementar sistema completo de autenticaci贸n JWT incluyendo registro, login, middleware de protecci贸n, refresh tokens, roles y permisos, rate limiting y logging de seguridad"
```

#### **Output Esperado:**
- Lista de subtareas espec铆ficas
- Orden de implementaci贸n sugerido
- Dependencias entre subtareas
- Criterios de aceptaci贸n por subtarea

#### **Validaci贸n:**
- [ ] Subtareas cubren toda la funcionalidad
- [ ] Son independientes y ejecutables
- [ ] Orden de implementaci贸n es l贸gico
- [ ] Tama帽o de subtareas es manejable

---

### **Comando 7: estimate_effort**

#### **Objetivo:** Estimar esfuerzo requerido
#### **Input:** Descripci贸n de feature o proyecto
#### **Ejecuci贸n:**

1. **Feature peque帽a:**
   ```
   estimate_effort "Agregar endpoint GET /users para listar usuarios con paginaci贸n y filtros b谩sicos"
   ```

2. **Feature mediana:**
   ```
   estimate_effort "Sistema de notificaciones push con WebSocket, email fallback y dashboard de administraci贸n"
   ```

3. **Proyecto grande:**
   ```
   estimate_effort "Plataforma completa de e-commerce con cat谩logo de productos, carrito de compras, procesamiento de pagos, gesti贸n de inventario y panel de administraci贸n"
   ```

#### **Output Esperado:**
- Estimaci贸n en story points y/o horas
- Desglose por componentes
- Factores que afectan la estimaci贸n
- Rango de confianza

#### **Validaci贸n:**
- [ ] Estimaciones son realistas
- [ ] Desglose es detallado
- [ ] Factores de riesgo considerados
- [ ] Rangos de confianza apropiados

---

### **Comando 8: generate_subtasks**

#### **Objetivo:** Generar subtareas detalladas para 茅picas
#### **Input:** Epic o historia de usuario grande
#### **Ejecuci贸n:**

```
generate_subtasks "Como administrador del sistema, quiero implementar un dashboard completo de analytics que me permita ver m茅tricas de usuarios, performance de la aplicaci贸n, errores en tiempo real, y generar reportes personalizados para tomar decisiones informadas sobre el producto"
```

#### **Output Esperado:**
- Subtareas con formato de historia de usuario
- Criterios de aceptaci贸n espec铆ficos
- Tasks t茅cnicas de implementaci贸n
- Tests de aceptaci贸n

#### **Validaci贸n:**
- [ ] Subtareas siguen formato est谩ndar
- [ ] Criterios son espec铆ficos y testeable
- [ ] Cobertura completa del epic
- [ ] Tareas t茅cnicas incluidas

---

##  Validaci贸n de Resultados

### **Dashboard de Progreso**
```bash
cd .ai-methodology/sync
npm run dashboard
```

### **Verificar Issues en GitHub**
```bash
# Ver issues abiertos
curl -H "Authorization: token $GITHUB_TOKEN" \
     https://api.github.com/repos/jivagrisma/dev-ia/issues?state=open

# Ver proyecto GitHub
curl -H "Authorization: token $GITHUB_TOKEN" \
     https://api.github.com/users/jivagrisma/projects
```

### **M茅tricas Actualizadas**
```bash
cat docs/metrics.md
```

---

##  Documentar Resultados

### **Template de Resultados**
Para cada comando probado, documentar:

```markdown
## Comando: [nombre_comando]

### Input:
[descripci贸n del input usado]

### Output:
[resultado obtenido]

### Tiempo de Ejecuci贸n:
[tiempo que tom贸]

### Calidad del Output:
- Precisi贸n: [1-10]
- Completitud: [1-10]
- Utilidad: [1-10]

### Observaciones:
[notas adicionales]

### Recomendaciones:
[mejoras sugeridas]
```

---

##  Criterios de xito

### **Para GitHub Project Manager:**
- [ ] PRDs generados son completos y 煤tiles
- [ ] Parsing de PRDs produce tareas ejecutables
- [ ] Sincronizaci贸n crea issues correctamente
- [ ] Status del proyecto es preciso

### **Para Task Master AI:**
- [ ] An谩lisis de complejidad es consistente
- [ ] Breakdown de tareas es 煤til
- [ ] Estimaciones son realistas
- [ ] Subtareas generadas son espec铆ficas

### **Para Integraci贸n:**
- [ ] Comandos funcionan sin errores
- [ ] Outputs se integran con flujo existente
- [ ] Dashboard refleja cambios autom谩ticamente
- [ ] Metodolog铆a completa funciona end-to-end

---

##  Pr贸ximos Pasos

1. **Ejecutar todas las pruebas** siguiendo esta gu铆a
2. **Documentar resultados** usando el template
3. **Identificar mejoras** en la integraci贸n
4. **Optimizar configuraci贸n** MCP si es necesario
5. **Crear casos de uso** adicionales
6. **Entrenar al equipo** en el uso de comandos MCP

---

*Gu铆a creada para validar la metodolog铆a completa de desarrollo con IA*
